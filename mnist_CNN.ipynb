{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.65\n",
      "Epoch 1, loss: 0.63\n",
      "Epoch 2, loss: 0.57\n",
      "Epoch 3, loss: 0.55\n",
      "Epoch 4, loss: 0.49\n",
      "Epoch 5, loss: 0.46\n",
      "Epoch 6, loss: 0.43\n",
      "Epoch 7, loss: 0.39\n",
      "Epoch 8, loss: 0.36\n",
      "Epoch 9, loss: 0.35\n",
      "Testing score f1: 0.8218875502008032\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "from numpy import unique, array, vectorize\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class CNNClassifier:\n",
    "\n",
    "    def __init__(self, train_data=None):\n",
    "        data, labels = train_data\n",
    "\n",
    "        labels = self._transform_labels(labels)\n",
    "        data = self._transform_input(data)\n",
    "        \n",
    "        self.train_data = (data, labels)\n",
    "\n",
    "        self.assemble_graph()\n",
    "\n",
    "        self._open_session()\n",
    "\n",
    "        if train_data:\n",
    "            self.train()     \n",
    "\n",
    "    def assemble_graph(self, learning_rate = 0.02):\n",
    "        data, labels = self.train_data\n",
    "        \n",
    "        self.input_data = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name=\"input_data\")\n",
    "        self.output_labels = tf.placeholder(tf.float32, shape=[None, 1], name=\"output_labels\")\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(\n",
    "            inputs=self.input_data,\n",
    "            filters=3,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=3,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 3])\n",
    "        \n",
    "        dense = tf.layers.dense(inputs=pool2_flat, units=4, activation=tf.nn.relu)\n",
    "        \n",
    "        logits = tf.layers.dense(inputs=dense, units=1)\n",
    "\n",
    "        self.output = tf.nn.sigmoid(logits, name=\"softmax_tensor\")\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=self.output_labels, logits=logits))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        self.training = optimizer.minimize(self.loss)\n",
    "        \n",
    "\n",
    "    def train(self, epochs=10, minibatch_size=256):\n",
    "        minibatches = self._create_minibatches(minibatch_size)\n",
    "        sess = self.sess\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for data, labels in minibatches:\n",
    "                sess.run(self.training, {self.input_data: data, self.output_labels: labels})\n",
    "\n",
    "            loss_val = sess.run(self.loss, {self.input_data: minibatches[0][0], self.output_labels: minibatches[0][1]})\n",
    "            print(\"Epoch %d, loss: %.2f\" % (e, loss_val))\n",
    "\n",
    "    def predict(self, data):\n",
    "        data = self._transform_input(data)\n",
    "        \n",
    "        predict = self.sess.run(self.output, {self.input_data: data})\n",
    "        \n",
    "        for i in range(len(predict)):\n",
    "            if predict[i] > 0.5:\n",
    "                predict[i] = 1\n",
    "            else:\n",
    "                predict[i] = 0\n",
    "                \n",
    "        return predict\n",
    "\n",
    "    def _create_minibatches(self, minibatch_size):\n",
    "        pos = 0\n",
    "\n",
    "        data, labels = self.train_data\n",
    "        n_samples = len(labels)\n",
    "\n",
    "        batches = []\n",
    "        while pos + minibatch_size < n_samples:\n",
    "            batches.append((data[pos:pos+minibatch_size,:], labels[pos:pos+minibatch_size]))\n",
    "            pos += minibatch_size\n",
    "\n",
    "        if pos < n_samples:\n",
    "            batches.append((data[pos:n_samples,:], labels[pos:n_samples,:]))\n",
    "\n",
    "        return batches\n",
    "\n",
    "    def _transform_labels(self, labels):\n",
    "        labels = labels.reshape((-1, 1))\n",
    "        return labels\n",
    "        \n",
    "\n",
    "    def _transform_input(self, data):\n",
    "        data = data.reshape((-1, 28, 28, 1))\n",
    "        return data\n",
    "\n",
    "    def _open_session(self):\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "\n",
    "    def mnist_to_binary(train_data, train_label, test_data, test_label):\n",
    "\n",
    "        binarized_labels = []\n",
    "        for labels in [train_label, test_label]:\n",
    "            remainder_2 = vectorize(lambda x: x%2)\n",
    "            binarized_labels.append(remainder_2(labels))\n",
    "\n",
    "        train_label, test_label = binarized_labels\n",
    "\n",
    "        return train_data, train_label, test_data, test_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ((train_data, train_labels),\n",
    "        (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    train_data, train_labels, test_data, test_labels = mnist_to_binary(train_data, train_labels, eval_data, eval_labels)\n",
    "\n",
    "    cnn = CNNClassifier((train_data, train_labels))\n",
    "    print(\"Testing score f1: {}\".format(f1_score(test_labels, cnn.predict(test_data))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
