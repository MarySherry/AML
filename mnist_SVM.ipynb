{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 188.64\n",
      "Epoch 1, loss: 185.67\n",
      "Epoch 2, loss: 206.55\n",
      "Epoch 3, loss: 213.81\n",
      "Epoch 4, loss: 213.91\n",
      "Epoch 5, loss: 209.60\n",
      "Epoch 6, loss: 283.82\n",
      "Epoch 7, loss: 251.64\n",
      "Epoch 8, loss: 241.48\n",
      "Epoch 9, loss: 204.78\n",
      "Epoch 10, loss: 329.82\n",
      "Epoch 11, loss: 189.57\n",
      "Epoch 12, loss: 214.51\n",
      "Epoch 13, loss: 226.71\n",
      "Epoch 14, loss: 224.63\n",
      "Epoch 15, loss: 214.44\n",
      "Epoch 16, loss: 208.76\n",
      "Epoch 17, loss: 212.81\n",
      "Epoch 18, loss: 265.86\n",
      "Epoch 19, loss: 207.91\n",
      "Testing score f1: 0.8922607118999905\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "from numpy import unique, array, vectorize\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class SVMClassifier:\n",
    "\n",
    "    def __init__(self, train_data=None):\n",
    "        data, labels = train_data\n",
    "\n",
    "        labels = self._transform_labels(labels)\n",
    "        data = self._flatten_input(data)\n",
    "        \n",
    "        self.train_data = (data, labels)\n",
    "\n",
    "        self.assemble_graph()\n",
    "\n",
    "        self._open_session()\n",
    "\n",
    "        if train_data:\n",
    "            self.train()     \n",
    "\n",
    "    def assemble_graph(self, learning_rate = 0.02):\n",
    "        data, labels = self.train_data\n",
    "        in_size = [None, data.shape[1]]\n",
    "        out_size = [None, labels.shape[1]]\n",
    "        \n",
    "        self.input_data = tf.placeholder(tf.float32, shape=in_size, name=\"input_data\")\n",
    "        self.output_labels = tf.placeholder(tf.float32, shape=out_size, name=\"output_labels\")\n",
    "        \n",
    "        weight = tf.get_variable(\"weight\", (in_size[1], 1), tf.float32)\n",
    "        bias = tf.get_variable(\"bias\", (1,1), tf.float32)\n",
    "        \n",
    "        inference = tf.matmul(self.input_data,weight) - bias\n",
    "        \n",
    "        self.output = tf.sign(inference)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.maximum(0., 1. - self.output_labels * inference))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        self.training = optimizer.minimize(self.loss)\n",
    "        \n",
    "\n",
    "    def train(self, epochs=20, minibatch_size=256):\n",
    "        minibatches = self._create_minibatches(minibatch_size)\n",
    "        sess = self.sess\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for data, labels in minibatches:\n",
    "                sess.run(self.training, {self.input_data: data, self.output_labels: labels})\n",
    "\n",
    "            loss_val = sess.run(self.loss, {self.input_data: minibatches[0][0], self.output_labels: minibatches[0][1]})\n",
    "            print(\"Epoch %d, loss: %.2f\" % (e, loss_val))\n",
    "\n",
    "    def predict(self, data):\n",
    "        data = self._flatten_input(data)\n",
    "        \n",
    "        predict = self.sess.run(self.output, {self.input_data: data})\n",
    "        \n",
    "        for i in range(len(predict)):\n",
    "            if predict[i] == -1:\n",
    "                predict[i] = 0\n",
    "        return predict\n",
    "\n",
    "    def _create_minibatches(self, minibatch_size):\n",
    "        pos = 0\n",
    "\n",
    "        data, labels = self.train_data\n",
    "        n_samples = len(labels)\n",
    "\n",
    "        batches = []\n",
    "        while pos + minibatch_size < n_samples:\n",
    "            batches.append((data[pos:pos+minibatch_size,:], labels[pos:pos+minibatch_size]))\n",
    "            pos += minibatch_size\n",
    "\n",
    "        if pos < n_samples:\n",
    "            batches.append((data[pos:n_samples,:], labels[pos:n_samples]))\n",
    "\n",
    "        return batches\n",
    "\n",
    "    def _transform_labels(self, labels):\n",
    "        labels = labels.reshape((-1, 1))\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == 0:\n",
    "                labels[i] = -1\n",
    "        return labels\n",
    "        \n",
    "\n",
    "    def _flatten_input(self, data):\n",
    "        size = data.shape[1] * data.shape[2]\n",
    "        data = data.reshape(data.shape[0], size)\n",
    "        return data\n",
    "\n",
    "    def _open_session(self):\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "\n",
    "    def mnist_to_binary(train_data, train_label, test_data, test_label):\n",
    "\n",
    "        binarized_labels = []\n",
    "        for labels in [train_label, test_label]:\n",
    "            remainder_2 = vectorize(lambda x: x%2)\n",
    "            binarized_labels.append(remainder_2(labels))\n",
    "\n",
    "        train_label, test_label = binarized_labels\n",
    "\n",
    "        return train_data, train_label, test_data, test_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ((train_data, train_labels),\n",
    "        (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    train_data, train_labels, test_data, test_labels = mnist_to_binary(train_data, train_labels, eval_data, eval_labels)\n",
    "\n",
    "    svm = SVMClassifier((train_data, train_labels))\n",
    "    print(\"Testing score f1: {}\".format(f1_score(test_labels, svm.predict(test_data))))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
